--- origsrc/httpd-2.4.12/include/httpd.h	2014-08-22 13:18:08.000000000 -0500
+++ src/httpd-2.4.12/include/httpd.h	2015-05-21 12:59:31.032214100 -0500
@@ -1019,10 +1019,12 @@ struct request_rec {
     /** There is no local copy of this response */
     int no_local_copy;
 
+#if APR_HAS_THREADS
     /** Mutex protect callbacks registered with ap_mpm_register_timed_callback
      * from being run before the original handler finishes running
      */
     apr_thread_mutex_t *invoke_mtx;
+#endif
 
     /** A struct containing the components of URI */
     apr_uri_t parsed_uri;
--- origsrc/httpd-2.4.12/modules/lua/lua_request.c	2014-09-05 09:20:27.000000000 -0500
+++ src/httpd-2.4.12/modules/lua/lua_request.c	2015-05-21 14:14:14.868088900 -0500
@@ -1312,10 +1312,12 @@ static int lua_ap_scoreboard_worker(lua_
         lua_pushnumber(L, (lua_Number) ws_record->stop_time);
         lua_settable(L, -3);
 
+#if APR_HAS_THREADS
         lua_pushstring(L, "tid");
 
         lua_pushinteger(L, (lua_Integer) ws_record->tid);
         lua_settable(L, -3);
+#endif
 
         lua_pushstring(L, "vhost");
         lua_pushstring(L, ws_record->vhost);
--- origsrc/httpd-2.4.12/modules/lua/mod_lua.c	2014-12-02 06:50:59.000000000 -0600
+++ src/httpd-2.4.12/modules/lua/mod_lua.c	2015-05-21 14:12:28.522584700 -0500
@@ -1623,7 +1623,7 @@ static const char *register_lua_scope(cm
         return apr_psprintf(cmd->pool,
                             "Scope type of '%s' cannot be used because this "
                             "server does not have threading support "
-                            "(APR_HAS_THREADS)" 
+                            "(APR_HAS_THREADS)",
                             scope);
 #endif
         cfg->vm_scope = AP_LUA_SCOPE_THREAD;
@@ -1634,7 +1634,7 @@ static const char *register_lua_scope(cm
         return apr_psprintf(cmd->pool,
                             "Scope type of '%s' cannot be used because this "
                             "server does not have threading support "
-                            "(APR_HAS_THREADS)" 
+                            "(APR_HAS_THREADS)",
                             scope);
 #endif
         cfg->vm_scope = AP_LUA_SCOPE_SERVER;
@@ -1968,7 +1968,9 @@ static void *create_server_config(apr_po
 
     ap_lua_server_cfg *cfg = apr_pcalloc(p, sizeof(ap_lua_server_cfg));
     cfg->vm_reslists = apr_hash_make(p);
+#if APR_HAS_THREADS
     apr_thread_rwlock_create(&cfg->vm_reslists_lock, p);
+#endif
     cfg->root_path = NULL;
 
     return cfg;
--- origsrc/httpd-2.4.12/modules/lua/mod_lua.h	2013-06-10 09:36:56.000000000 -0500
+++ src/httpd-2.4.12/modules/lua/mod_lua.h	2015-05-21 14:11:11.604817400 -0500
@@ -136,7 +136,9 @@ typedef struct
 typedef struct
 {
     apr_hash_t *vm_reslists;
+#if APR_HAS_THREADS
     apr_thread_rwlock_t *vm_reslists_lock;
+#endif
 
     /* value of the LuaRoot directive */
     const char *root_path;
--- origsrc/httpd-2.4.12/modules/proxy/mod_proxy.h	2015-01-14 07:28:00.000000000 -0600
+++ src/httpd-2.4.12/modules/proxy/mod_proxy.h	2015-05-21 13:05:42.274855900 -0500
@@ -409,7 +409,9 @@ struct proxy_worker {
     proxy_conn_pool     *cp;    /* Connection pool to use */
     proxy_worker_shared   *s;   /* Shared data */
     proxy_balancer  *balancer;  /* which balancer am I in? */
+#if APR_HAS_THREADS
     apr_thread_mutex_t  *tmutex; /* Thread lock for updating address cache */
+#endif
     void            *context;   /* general purpose storage */
 };
 
@@ -457,7 +459,9 @@ struct proxy_balancer {
     apr_time_t      wupdated;    /* timestamp of last change to workers list */
     proxy_balancer_method *lbmethod;
     apr_global_mutex_t  *gmutex; /* global lock for updating list of workers */
+#if APR_HAS_THREADS
     apr_thread_mutex_t  *tmutex; /* Thread lock for updating shm */
+#endif
     proxy_server_conf *sconf;
     void            *context;    /* general purpose storage */
     proxy_balancer_shared *s;    /* Shared data */
--- origsrc/httpd-2.4.12/modules/proxy/mod_proxy_balancer.c	2014-10-27 07:45:34.000000000 -0500
+++ src/httpd-2.4.12/modules/proxy/mod_proxy_balancer.c	2015-05-21 14:26:46.631050700 -0500
@@ -328,23 +328,27 @@ static proxy_worker *find_best_worker(pr
     proxy_worker *candidate = NULL;
     apr_status_t rv;
 
+#if APR_HAS_THREADS
     if ((rv = PROXY_THREAD_LOCK(balancer)) != APR_SUCCESS) {
         ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01163)
                       "%s: Lock failed for find_best_worker()",
                       balancer->s->name);
         return NULL;
     }
+#endif
 
     candidate = (*balancer->lbmethod->finder)(balancer, r);
 
     if (candidate)
         candidate->s->elected++;
 
+#if APR_HAS_THREADS
     if ((rv = PROXY_THREAD_UNLOCK(balancer)) != APR_SUCCESS) {
         ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01164)
                       "%s: Unlock failed for find_best_worker()",
                       balancer->s->name);
     }
+#endif
 
     if (candidate == NULL) {
         /* All the workers are in error state or disabled.
@@ -474,11 +478,13 @@ static int proxy_balancer_pre_request(pr
     /* Step 2: Lock the LoadBalancer
      * XXX: perhaps we need the process lock here
      */
+#if APR_HAS_THREADS
     if ((rv = PROXY_THREAD_LOCK(*balancer)) != APR_SUCCESS) {
         ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01166)
                       "%s: Lock failed for pre_request", (*balancer)->s->name);
         return DECLINED;
     }
+#endif
 
     /* Step 3: force recovery */
     force_recovery(*balancer, r->server);
@@ -539,20 +545,24 @@ static int proxy_balancer_pre_request(pr
             ap_log_rerror(APLOG_MARK, APLOG_ERR, 0, r, APLOGNO(01167)
                           "%s: All workers are in error state for route (%s)",
                           (*balancer)->s->name, route);
+#if APR_HAS_THREADS
             if ((rv = PROXY_THREAD_UNLOCK(*balancer)) != APR_SUCCESS) {
                 ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01168)
                               "%s: Unlock failed for pre_request",
                               (*balancer)->s->name);
             }
+#endif
             return HTTP_SERVICE_UNAVAILABLE;
         }
     }
 
+#if APR_HAS_THREADS
     if ((rv = PROXY_THREAD_UNLOCK(*balancer)) != APR_SUCCESS) {
         ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01169)
                       "%s: Unlock failed for pre_request",
                       (*balancer)->s->name);
     }
+#endif
     if (!*worker) {
         runtime = find_best_worker(*balancer, r);
         if (!runtime) {
@@ -626,12 +636,14 @@ static int proxy_balancer_post_request(p
 
     apr_status_t rv;
 
+#if APR_HAS_THREADS
     if ((rv = PROXY_THREAD_LOCK(balancer)) != APR_SUCCESS) {
         ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01173)
                       "%s: Lock failed for post_request",
                       balancer->s->name);
         return HTTP_INTERNAL_SERVER_ERROR;
     }
+#endif
 
     if (!apr_is_empty_array(balancer->errstatuses)) {
         int i;
@@ -662,10 +674,12 @@ static int proxy_balancer_post_request(p
 
     }
 
+#if APR_HAS_THREADS
     if ((rv = PROXY_THREAD_UNLOCK(balancer)) != APR_SUCCESS) {
         ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01175)
                       "%s: Unlock failed for post_request", balancer->s->name);
     }
+#endif
     ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r, APLOGNO(01176)
                   "proxy_balancer_post_request for (%s)", balancer->s->name);
 
@@ -1009,17 +1023,21 @@ static int balancer_handler(request_rec
 
     balancer = (proxy_balancer *)conf->balancers->elts;
     for (i = 0; i < conf->balancers->nelts; i++, balancer++) {
+#if APR_HAS_THREADS
         if ((rv = PROXY_THREAD_LOCK(balancer)) != APR_SUCCESS) {
             ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01189)
                           "%s: Lock failed for balancer_handler",
                           balancer->s->name);
         }
+#endif
         ap_proxy_sync_balancer(balancer, r->server, conf);
+#if APR_HAS_THREADS
         if ((rv = PROXY_THREAD_UNLOCK(balancer)) != APR_SUCCESS) {
             ap_log_rerror(APLOG_MARK, APLOG_ERR, rv, r, APLOGNO(01190)
                           "%s: Unlock failed for balancer_handler",
                           balancer->s->name);
         }
+#endif
     }
 
     if (r->args && (r->method_number == M_GET)) {
--- origsrc/httpd-2.4.12/modules/proxy/mod_proxy_ftp.c	2014-11-01 10:21:33.000000000 -0500
+++ src/httpd-2.4.12/modules/proxy/mod_proxy_ftp.c	2015-05-21 14:24:24.464497800 -0500
@@ -1108,12 +1108,14 @@ static int proxy_ftp_handler(request_rec
                   "connecting %s to %s:%d", url, connectname, connectport);
 
     if (worker->s->is_address_reusable) {
+#if APR_HAS_THREADS
         if (!worker->cp->addr) {
             if ((err = PROXY_THREAD_LOCK(worker->balancer)) != APR_SUCCESS) {
                 ap_log_rerror(APLOG_MARK, APLOG_ERR, err, r, APLOGNO(01037) "lock");
                 return HTTP_INTERNAL_SERVER_ERROR;
             }
         }
+#endif
         connect_addr = worker->cp->addr;
         address_pool = worker->cp->pool;
     }
@@ -1128,9 +1130,11 @@ static int proxy_ftp_handler(request_rec
                                     address_pool);
     if (worker->s->is_address_reusable && !worker->cp->addr) {
         worker->cp->addr = connect_addr;
+#if APR_HAS_THREADS
         if ((uerr = PROXY_THREAD_UNLOCK(worker->balancer)) != APR_SUCCESS) {
             ap_log_rerror(APLOG_MARK, APLOG_ERR, uerr, r, APLOGNO(01038) "unlock");
         }
+#endif
     }
     /*
      * get all the possible IP addresses for the destname and loop through
--- origsrc/httpd-2.4.12/modules/proxy/proxy_util.c	2015-01-14 07:28:00.000000000 -0600
+++ src/httpd-2.4.12/modules/proxy/proxy_util.c	2015-05-21 14:18:12.671286100 -0500
@@ -1176,7 +1176,9 @@ PROXY_DECLARE(char *) ap_proxy_define_ba
 
     (*balancer)->workers = apr_array_make(p, 5, sizeof(proxy_worker *));
     (*balancer)->gmutex = NULL;
+#if APR_HAS_THREADS
     (*balancer)->tmutex = NULL;
+#endif
     (*balancer)->lbmethod = lbmethod;
 
     if (do_malloc)
@@ -1305,6 +1307,7 @@ PROXY_DECLARE(apr_status_t) ap_proxy_ini
     if (balancer->lbmethod && balancer->lbmethod->reset)
         balancer->lbmethod->reset(balancer, s);
 
+#if APR_HAS_THREADS
     if (balancer->tmutex == NULL) {
         rv = apr_thread_mutex_create(&(balancer->tmutex), APR_THREAD_MUTEX_DEFAULT, p);
         if (rv != APR_SUCCESS) {
@@ -1313,6 +1316,7 @@ PROXY_DECLARE(apr_status_t) ap_proxy_ini
             return rv;
         }
     }
+#endif
     return APR_SUCCESS;
 }
 
@@ -1819,6 +1823,7 @@ PROXY_DECLARE(apr_status_t) ap_proxy_ini
                      ap_proxy_worker_name(p, worker));
         apr_global_mutex_lock(proxy_mutex);
         /* Now init local worker data */
+#if APR_HAS_THREADS
         if (worker->tmutex == NULL) {
             rv = apr_thread_mutex_create(&(worker->tmutex), APR_THREAD_MUTEX_DEFAULT, p);
             if (rv != APR_SUCCESS) {
@@ -1828,6 +1833,7 @@ PROXY_DECLARE(apr_status_t) ap_proxy_ini
                 return rv;
             }
         }
+#endif
         if (worker->cp == NULL)
             init_conn_pool(p, worker);
         if (worker->cp == NULL) {
@@ -2302,10 +2308,12 @@ ap_proxy_determine_connection(apr_pool_t
              * we can reuse the address.
              */
             if (!worker->cp->addr) {
+#if APR_HAS_THREADS
                 if ((err = PROXY_THREAD_LOCK(worker)) != APR_SUCCESS) {
                     ap_log_rerror(APLOG_MARK, APLOG_ERR, err, r, APLOGNO(00945) "lock");
                     return HTTP_INTERNAL_SERVER_ERROR;
                 }
+#endif
 
                 /*
                  * Worker can have the single constant backend adress.
@@ -2318,9 +2326,11 @@ ap_proxy_determine_connection(apr_pool_t
                                             conn->port, 0,
                                             worker->cp->pool);
                 conn->addr = worker->cp->addr;
+#if APR_HAS_THREADS
                 if ((uerr = PROXY_THREAD_UNLOCK(worker)) != APR_SUCCESS) {
                     ap_log_rerror(APLOG_MARK, APLOG_ERR, uerr, r, APLOGNO(00946) "unlock");
                 }
+#endif
             }
             else {
                 conn->addr = worker->cp->addr;
@@ -3112,7 +3122,9 @@ PROXY_DECLARE(apr_status_t) ap_proxy_syn
             (*runtime)->cp = NULL;
             (*runtime)->balancer = b;
             (*runtime)->s = shm;
+#if APR_HAS_THREADS
             (*runtime)->tmutex = NULL;
+#endif
             rv = ap_proxy_initialize_worker(*runtime, s, conf->pool);
             if (rv != APR_SUCCESS) {
                 ap_log_error(APLOG_MARK, APLOG_EMERG, rv, s, APLOGNO(00966) "Cannot init worker");
--- origsrc/httpd-2.4.12/modules/test/mod_dialup.c	2012-04-04 15:11:57.000000000 -0500
+++ src/httpd-2.4.12/modules/test/mod_dialup.c	2015-05-21 15:44:41.137637600 -0500
@@ -106,7 +106,9 @@ dialup_callback(void *baton)
     int status;
     dialup_baton_t *db = (dialup_baton_t *)baton;
 
+#if APR_HAS_THREADS
     apr_thread_mutex_lock(db->r->invoke_mtx);
+#endif
 
     status = dialup_send_pulse(db);
 
@@ -114,7 +116,9 @@ dialup_callback(void *baton)
         ap_mpm_register_timed_callback(apr_time_from_sec(1), dialup_callback, baton);
     }
     else if (status == DONE) {
+#if APR_HAS_THREADS
         apr_thread_mutex_unlock(db->r->invoke_mtx);
+#endif
         ap_finalize_request_protocol(db->r);
         ap_process_request_after_handler(db->r);
         return;
@@ -126,7 +130,9 @@ dialup_callback(void *baton)
         ap_die(status, db->r);
     }
 
+#if APR_HAS_THREADS
     apr_thread_mutex_unlock(db->r->invoke_mtx);
+#endif
 }
 
 static int
